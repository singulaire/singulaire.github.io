<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>design of experiments on Tom Blau - But It Could Be Better</title>
    <link>https://singulaire.github.io/tags/design-of-experiments/</link>
    <description>Recent content in design of experiments on Tom Blau - But It Could Be Better</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://singulaire.github.io/tags/design-of-experiments/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Bounds on Bounds</title>
      <link>https://singulaire.github.io/post/bounds-on-bounds/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://singulaire.github.io/post/bounds-on-bounds/</guid>
      <description>This is a TODO that reminds me to eventually write a post on limitations of MI estimators and alternative solutions.</description>
    </item>
    
    <item>
      <title>Reinforcement Learning for Design of Experiments</title>
      <link>https://singulaire.github.io/post/rl-boed/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://singulaire.github.io/post/rl-boed/</guid>
      <description>This is a TODO that reminds me to eventually write a post on My recent paper and where we can go next.</description>
    </item>
    
    <item>
      <title>Upper and Lower Mutual Information Bounds</title>
      <link>https://singulaire.github.io/post/upper-and-lower-mutual-information-bounds/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://singulaire.github.io/post/upper-and-lower-mutual-information-bounds/</guid>
      <description>Recently Foster et al (2020) introduced a couple of tractable bounds that can be used to estimate the expected information gain (EIG) of a design policy (a mapping from past designs and observations to the next design). These include the sequential Prior Contrastive Estimate (sPCE) lower bound:
$$ \mathcal{L}_T(\pi) = \mathbb{E} \left[ \log \frac{p(h_T | \theta_0, \pi)}{\frac{1}{L+1} \sum_0^L p(h_T | \theta_l, \pi)} \right] $$
where $h_T = (d_0, y_0,\dots,d_T,y_T)$ is the experimental history at time $T$, $\pi$ is the design policy, $L$ is the number of contrastiv samples and $\theta$ parameterises the experimental model $p(y|\theta, d)$ that maps designs to a distribution over outcomes.</description>
    </item>
    
  </channel>
</rss>
